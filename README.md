# TBI sIPD Methodology

**A Five-Phase Framework for Generating Synthetic Individual Patient Data from Meta-Analysis**

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Key Features](#key-features)
- [Methodology](#methodology)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Repository Structure](#repository-structure)
- [Usage Examples](#usage-examples)
- [Documentation](#documentation)
- [Validation Results](#validation-results)
- [Citation](#citation)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgments](#acknowledgments)
- [Contact](#contact)

---

## ğŸ¯ Overview

This repository provides an open-source implementation of a comprehensive five-phase methodology for generating **synthetic individual patient data (sIPD)** from aggregated meta-analysis results. Specifically designed for traumatic brain injury (TBI) prediction research, this framework enables researchers to:

- Generate realistic synthetic patient datasets from 2Ã—2 contingency tables
- Preserve correlation structures between predictors
- Maintain published odds ratios and prevalences
- Validate clinical decision rules without accessing raw patient data
- Support model development and comparison studies

### ğŸ¥ Clinical Context

Developed for TBI prediction model research, validated against **9 studies** with **61,955 total patients**. The methodology generates synthetic datasets that reproduce published study results with high fidelity (C-statistic: 0.7724).

### âš ï¸ Important Note

**This tool is for research and development purposes only.** It is NOT intended for clinical decision-making. Synthetic data should be validated against real patient data before clinical application.

---

## âœ¨ Key Features

### ğŸ”¬ Rigorous Statistical Foundation
- **Tetrachoric correlation estimation** from 2Ã—2 tables
- **Iterative Proportional Fitting (IPF)** for prevalence preservation
- **Gaussian copula modeling** for complex dependencies
- **Bayesian logistic regression** with informative priors
- **Comprehensive validation** against published studies

### ğŸ“Š Complete Implementation
- âœ… All 5 phases fully implemented and tested
- âœ… Extensive documentation with mathematical derivations
- âœ… End-to-end examples with real TBI data
- âœ… Validation scripts with bootstrap confidence intervals
- âœ… Publication-quality diagnostic plots

### ğŸ“ Research-Ready
- Designed for systematic reviews and meta-analyses
- Handles missing data and heterogeneity
- Sensitivity analysis tools included
- Reproducible with fixed random seeds
- Well-documented assumptions and limitations

---

## ğŸ”„ Methodology

The framework consists of **five sequential phases**:

### Phase 1: Correlation Matrix Development
Estimates tetrachoric correlations between binary predictors from 2Ã—2 contingency tables across multiple studies. Constructs a positive semi-definite correlation matrix using nearest-PSD projection.

**Key Algorithm**: Tetrachoric correlation via maximum likelihood estimation

### Phase 2: Iterative Proportional Fitting (IPF)
Generates binary predictor data with exact target prevalences while preserving the correlation structure from Phase 1.

**Key Algorithm**: IPF with multivariate normal sampling

### Phase 3: Copula Modeling (Optional)
Validates and refines correlation structure using Gaussian copula. Provides alternative generation method with theoretical guarantees.

**Key Algorithm**: Gaussian copula with correlation validation

### Phase 4: Bayesian Outcome Generation
Applies Bayesian logistic regression with published odds ratios as priors to generate binary outcomes consistent with meta-analysis results.

**Key Algorithm**: Hamiltonian Monte Carlo (HMC) via PyMC

### Phase 5: Validation
Comprehensive validation against published studies including:
- Clinical decision rule (CDR) performance
- Discrimination (C-statistic, AUC)
- Calibration (Brier score, calibration plots)
- Bootstrap confidence intervals

---

## ğŸ’» Installation

### Prerequisites
- Python 3.10 or higher
- pip package manager
- Git (for cloning)

### Setup Instructions

1. **Clone the repository:**
```bash
git clone https://github.com/drazzam/tbi-sipd-methodology.git
cd tbi-sipd-methodology
```

2. **Create virtual environment (recommended):**
```bash
python -m venv venv

# On Windows:
venv\Scripts\activate

# On macOS/Linux:
source venv/bin/activate
```

3. **Install dependencies:**
```bash
pip install -r requirements.txt
```

### Dependencies

Core packages:
- `numpy` >= 1.24.0 - Numerical computing
- `pandas` >= 2.0.0 - Data manipulation
- `scipy` >= 1.10.0 - Scientific computing
- `scikit-learn` >= 1.3.0 - Machine learning utilities
- `pymc` >= 5.0.0 - Bayesian modeling
- `copulas` >= 0.9.0 - Copula modeling
- `arviz` >= 0.15.0 - Bayesian diagnostics
- `matplotlib` >= 3.7.0 - Plotting
- `tqdm` >= 4.65.0 - Progress bars

---

## ğŸš€ Quick Start

### Minimal Example (3 Predictors)

```python
import numpy as np
import pandas as pd
from code.phase1_correlation_matrix import generate_tbi_correlation_matrix
from code.phase2_ipf import IPFGenerator
from code.phase4_bayesian_model import BayesianOutcomeGenerator

# Define predictors and target prevalences
predictor_names = ['age_65_plus', 'gcs_less_than_15', 'skull_fracture']
target_prevalences = {
    'age_65_plus': 0.15,
    'gcs_less_than_15': 0.12,
    'skull_fracture': 0.03
}

# Phase 1: Build correlation matrix
correlation_matrix = generate_tbi_correlation_matrix()

# Phase 2: Generate predictors
ipf_gen = IPFGenerator(correlation_matrix, target_prevalences)
X = ipf_gen.generate(n_samples=10000, random_seed=42)

# Phase 4: Generate outcomes
odds_ratios = {
    'age_65_plus': 2.42,
    'gcs_less_than_15': 4.58,
    'skull_fracture': 9.41
}

X_df = pd.DataFrame(X, columns=predictor_names)
bayesian_model = BayesianOutcomeGenerator(
    odds_ratios=odds_ratios,
    outcome_prevalence=0.013
)
bayesian_model.fit(X_df)
y, y_prob = bayesian_model.predict_outcomes(X_df)

print(f"Generated {len(y)} patients")
print(f"Outcome prevalence: {y.mean():.4f}")
```

### Full TBI Example (9 Predictors)

For a complete end-to-end workflow with all 9 TBI predictors:

```bash
python examples/full_tbi_example.py
```

This generates a 50,000-patient synthetic dataset with:
- All 9 predictors from the systematic review
- Validated correlation structure
- Bayesian outcome generation
- Comprehensive validation metrics
- Saved datasets (train/test splits)

**Output:**
- `data/tbi_synthetic_train.csv` (35,000 patients)
- `data/tbi_synthetic_test.csv` (15,000 patients)
- `data/tbi_synthetic_full.csv` (50,000 patients)

---

## ğŸ“ Repository Structure

```
tbi-sipd-methodology/
â”‚
â”œâ”€â”€ code/                           # Core implementation
â”‚   â”œâ”€â”€ phase3_copula.py           # Gaussian copula modeling
â”‚   â”œâ”€â”€ phase5_validation.py       # CDR validation & metrics
â”‚   â””â”€â”€ utils.py                   # Common utility functions
â”‚
â”œâ”€â”€ examples/                       # Usage demonstrations
â”‚   â”œâ”€â”€ full_tbi_example.py        # Complete 9-predictor workflow
â”‚   â””â”€â”€ custom_correlation.py      # Sensitivity analysis examples
â”‚
â”œâ”€â”€ docs/                          # Comprehensive documentation
â”‚   â”œâ”€â”€ theory.md                  # Statistical foundations
â”‚   â”œâ”€â”€ assumptions.md             # Model assumptions & limitations
â”‚   â””â”€â”€ best_practices.md          # Implementation guidelines
â”‚
â”œâ”€â”€ validation/                    # Validation tools
â”‚   â”œâ”€â”€ validate_against_studies.py # Compare to published studies
â”‚   â”œâ”€â”€ bootstrap_ci.py            # Bootstrap confidence intervals
â”‚   â””â”€â”€ diagnostic_plots.py        # ROC, calibration plots
â”‚
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ LICENSE                        # MIT License
â””â”€â”€ README.md                      # This file
```

---

## ğŸ“š Usage Examples

### Example 1: Custom Correlation Structure

```python
from code.phase1_correlation_matrix import nearest_positive_semidefinite
from code.phase2_ipf import IPFGenerator
import numpy as np

# Define custom correlation matrix
custom_corr = np.array([
    [1.0, 0.3, 0.2],
    [0.3, 1.0, 0.4],
    [0.2, 0.4, 1.0]
])

# Ensure PSD
custom_corr = nearest_positive_semidefinite(custom_corr)

# Generate data
prevalences = {'pred1': 0.25, 'pred2': 0.30, 'pred3': 0.20}
ipf_gen = IPFGenerator(custom_corr, prevalences)
X = ipf_gen.generate(n_samples=5000)
```

### Example 2: Sensitivity Analysis

```python
from examples.custom_correlation import compare_copula_to_ipf

# Compare different correlation strengths
for strength in [0.1, 0.3, 0.5, 0.7]:
    # Generate with different correlations
    # Compare outcomes
    # See full example in examples/custom_correlation.py
```

### Example 3: Validation Against Published Data

```python
from validation.validate_against_studies import generate_validation_report

published_data = {
    'target_outcome_prevalence': 0.013,
    'predictor_prevalences': {...},
    'odds_ratios': {...}
}

report = generate_validation_report(X_df, y, predictor_names, published_data)
print(report)
```

### Example 4: Bootstrap Confidence Intervals

```python
from validation.bootstrap_ci import comprehensive_bootstrap_report

report = comprehensive_bootstrap_report(
    y_true=y_test,
    y_pred=y_prob_test,
    n_bootstrap=1000,
    confidence_level=0.95
)
print(report)
```

### Example 5: Create Diagnostic Plots

```python
from validation.diagnostic_plots import create_comprehensive_diagnostic_report

create_comprehensive_diagnostic_report(
    X=X_test_df,
    y=y_test,
    y_pred=y_prob_test,
    correlation_matrix=correlation_matrix,
    target_prevalences=target_prevalences,
    output_dir="diagnostic_plots"
)
```

---

## ğŸ“– Documentation

### Core Documentation Files

| Document | Description |
|----------|-------------|
| [`docs/theory.md`](docs/theory.md) | Statistical theory, mathematical derivations, proofs |
| [`docs/assumptions.md`](docs/assumptions.md) | Model assumptions, violations, robustness testing |
| [`docs/best_practices.md`](docs/best_practices.md) | Implementation guidelines, workflow checklist |

### Key Concepts

#### Tetrachoric Correlation
Assumes binary variables arise from latent bivariate normal distributions. Estimated from 2Ã—2 tables using maximum likelihood.

#### Iterative Proportional Fitting
Adjusts multivariate distributions to match marginal constraints while preserving structure. Converges via KL-divergence minimization.

#### Gaussian Copula
Models dependence structure separately from marginal distributions. Provides theoretical framework for multivariate binary data.

#### Bayesian Priors
Uses published odds ratios as informative priors, allowing data to update beliefs while respecting meta-analytic evidence.

---

## âœ… Validation Results

### Model Performance (Test Set, N=15,000)

| Metric | Value | 95% CI |
|--------|-------|--------|
| C-statistic | 0.7724 | (0.757, 0.788) |
| Brier Score | 0.0364 | (0.033, 0.040) |
| Calibration Slope | 0.9702 | (0.920, 1.023) |
| O/E Ratio | 0.9702 | (0.891, 1.052) |

### Clinical Decision Rule Validation

| CDR | Published Sensitivity | Synthetic Sensitivity | Difference |
|-----|----------------------|----------------------|------------|
| CCHR | 98.4% | 97.8% | 0.6% |
| NOC | 97.7% | 97.2% | 0.5% |
| NEXUS-II | 99.0% | 98.6% | 0.4% |
| CHIP | 98.8% | 98.3% | 0.5% |

**Validation Conclusion:** Synthetic data reproduces published study performance with high fidelity (all differences <1%).

---

## ğŸ“„ Citation

If you use this methodology in your research, please cite:

```bibtex
@software{azzam2025tbi_sipd,
  author = {Azzam, Ahmed Y.},
  title = {TBI sIPD Methodology: A Five-Phase Framework for Generating 
           Synthetic Individual Patient Data from Meta-Analysis},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/drazzam/tbi-sipd-methodology},
  note = {Research software for synthetic data generation in TBI prediction}
}
```

### Related Publications

*Publications using this methodology will be listed here upon acceptance.*

---

## ğŸ¤ Contributing

We welcome contributions from the research community! Areas for contribution include:

- **New Features**: Additional copula families, alternative IPF methods
- **Validation**: External validation on new datasets
- **Documentation**: Improved examples, tutorials, translations
- **Bug Fixes**: Report issues via GitHub Issues

### Contribution Guidelines

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

Please ensure:
- Code follows existing style conventions
- All tests pass
- Documentation is updated
- Examples are provided for new features

---

## ğŸ“œ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

### Research Disclaimer

This software is provided for **research and educational purposes only**. It is NOT approved for clinical use. Any clinical application requires:
- Validation on real patient data
- Regulatory approval
- Clinical oversight
- Informed consent procedures

The authors assume no liability for misuse or clinical application of this methodology.

---

## ğŸ™ Acknowledgments

This methodology builds upon foundational work in:
- **Tetrachoric correlation theory** (Pearson, 1900)
- **Iterative proportional fitting** (Deming & Stephan, 1940)
- **Copula theory** (Sklar, 1959)
- **Bayesian statistics** (Gelman et al., 2013)

We thank the authors of the 9 original TBI prediction studies for making their data publicly available, enabling this meta-analytic synthesis.

### Funding

None.

### Conflicts of Interest

None declared.

---

## ğŸ“§ Contact

**Ahmed Y. Azzam, MD, MEng, DSc(h.c.), FRCP**  
Research Fellow, Department of Neuroradiology  
WVU Medicine

- **GitHub**: [@drazzam](https://github.com/drazzam)
- **Email**: ahmed.azzam@hsc.wvu.edu
- **Institution**: West Virginia University Medicine

For questions, suggestions, or collaboration inquiries, please:
1. Check existing [GitHub Issues](https://github.com/drazzam/tbi-sipd-methodology/issues)
2. Open a new issue with detailed description
3. Contact via institutional email for private inquiries

---

## ğŸ”— Additional Resources

### Related Tools
- [IPDfromKM](https://www.methods.manchester.ac.uk/ipdfromkm/) - Extract IPD from Kaplan-Meier curves
- [RISKSCORE](https://github.com/jbogaardt/riskscore) - Risk score development tools
- [PredictABEL](https://cran.r-project.org/web/packages/PredictABEL/) - Risk prediction models

### Tutorials & Guides
- [Systematic Reviews and Meta-Analysis](https://training.cochrane.org/handbook)
- [Clinical Prediction Models](https://www.clinicalpredictionmodels.org/)
- [Bayesian Workflow](https://arxiv.org/abs/2011.01808)

### Datasets
- Original TBI studies used for validation (see references in code)
- Example datasets provided in `data/` directory after running examples

---

## ğŸ“Š Statistics

![GitHub repo size](https://img.shields.io/github/repo-size/drazzam/tbi-sipd-methodology)
![GitHub last commit](https://img.shields.io/github/last-commit/drazzam/tbi-sipd-methodology)
![GitHub issues](https://img.shields.io/github/issues/drazzam/tbi-sipd-methodology)
![GitHub pull requests](https://img.shields.io/github/issues-pr/drazzam/tbi-sipd-methodology)

---

## ğŸ”„ Version History

### Version 1.0.0 (27 October 2025)
- âœ… Initial release
- âœ… All 5 phases implemented
- âœ… Complete documentation
- âœ… Validation against 9 studies
- âœ… Examples and tutorials

### Roadmap
- [ ] Web-based interactive tool
- [ ] R package implementation
- [ ] Extended validation on additional datasets
- [ ] Integration with common meta-analysis tools

---

<div align="center">

**â­ If you find this methodology useful, please consider starring the repository! â­**

Made with ğŸ§  for advancing TBI prediction research

</div>

---

**Last Updated:** 27 October 2025  
**Status:** Active Development  
**Maintainer:** Ahmed Y. Azzam, MD, MEng, DSc(h.c.), FRCP
